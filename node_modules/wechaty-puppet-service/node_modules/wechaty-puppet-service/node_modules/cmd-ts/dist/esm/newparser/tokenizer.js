import { enumerate } from '../utils';
/**
 * Tokenize a list of arguments
 *
 * @param strings arguments, based on `process.argv`
 */
export function tokenize(strings) {
    let tokens = [];
    let overallIndex = 0;
    const push = (token) => {
        tokens.push(token);
        overallIndex += token.raw.length;
    };
    for (const [stringIndex, string] of enumerate(strings)) {
        const chars = [...string];
        for (let i = 0; i < chars.length; i++) {
            if (chars[i] === '-' && chars[i + 1] === '-') {
                push({ type: 'longPrefix', raw: '--', index: overallIndex });
                i++;
            }
            else if (chars[i] === '-') {
                push({ type: 'shortPrefix', raw: '-', index: overallIndex });
            }
            else {
                push({ type: 'char', raw: chars[i], index: overallIndex });
            }
        }
        if (stringIndex + 1 !== strings.length) {
            push({ type: 'argumentDivider', raw: ' ', index: overallIndex });
        }
    }
    return tokens;
}
//# sourceMappingURL=tokenizer.js.map